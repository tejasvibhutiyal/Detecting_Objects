{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glasses:1\n",
    "import os\n",
    "\n",
    "def update_class_ids(labels_dir, new_class_id):\n",
    "    # List all label .txt files in the directory\n",
    "    label_files = [f for f in os.listdir(labels_dir) if f.endswith('.txt')]\n",
    "    \n",
    "    # Update class IDs in the label files\n",
    "    for label_file in label_files:\n",
    "        file_path = os.path.join(labels_dir, label_file)\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        with open(file_path, 'w') as file:\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if parts[0] == '0':  # Check if the original class is 1\n",
    "                    parts[0] = new_class_id  # Change the class ID to the new one\n",
    "                else :\n",
    "                    parts[0] = '0'  # Set to -1 for classes other than 1\n",
    "                # Write the updated line back to the file\n",
    "                file.write(' '.join(parts) + '\\n')\n",
    "\n",
    "# Define your directories for the pen dataset\n",
    "base_dir = 'glasses_yolomodel_dataset'  # Replace with your actual directory path\n",
    "train_labels_dir = os.path.join(base_dir, 'train/labels')\n",
    "valid_labels_dir = os.path.join(base_dir, 'valid/labels')\n",
    "test_labels_dir = os.path.join(base_dir, 'test/labels')\n",
    "\n",
    "# Update class IDs to '80' for pen\n",
    "update_class_ids(train_labels_dir, '1')\n",
    "update_class_ids(valid_labels_dir, '1')\n",
    "update_class_ids(test_labels_dir, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def update_class_ids(labels_dir, new_class_id):\n",
    "    # List all label .txt files in the directory\n",
    "    label_files = [f for f in os.listdir(labels_dir) if f.endswith('.txt')]\n",
    "    \n",
    "    # Update class IDs in the label files\n",
    "    for label_file in label_files:\n",
    "        file_path = os.path.join(labels_dir, label_file)\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        with open(file_path, 'w') as file:\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if parts[0] == '0': \n",
    "                    parts[0] = new_class_id  \n",
    "                else :\n",
    "                    parts[0] = '-1'  # Set to -1 for classes other than 1\n",
    "                # Write the updated line back to the file\n",
    "                file.write(' '.join(parts) + '\\n')\n",
    "\n",
    "# Define your directories for the pen dataset\n",
    "base_dir = 'GlassesDataset2'  # Replace with your actual directory path\n",
    "train_labels_dir = os.path.join(base_dir, 'train/labels')\n",
    "valid_labels_dir = os.path.join(base_dir, 'valid/labels')\n",
    "test_labels_dir = os.path.join(base_dir, 'test/labels')\n",
    "\n",
    "# Update class IDs to '80' for pen\n",
    "update_class_ids(train_labels_dir, '1')\n",
    "update_class_ids(valid_labels_dir, '1')\n",
    "update_class_ids(test_labels_dir, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pen :3\n",
    "\n",
    "\n",
    "# Define your directories for the pen dataset\n",
    "base_dir = 'PenDataset2'  # Replace with your actual directory path\n",
    "train_labels_dir = os.path.join(base_dir, 'train/labels')\n",
    "valid_labels_dir = os.path.join(base_dir, 'valid/labels')\n",
    "#test_labels_dir = os.path.join(base_dir, 'test/labels')\n",
    "\n",
    "# Update class IDs to '80' for pen\n",
    "update_class_ids(train_labels_dir, '3')\n",
    "update_class_ids(valid_labels_dir, '3')\n",
    "#update_class_ids(test_labels_dir, '3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                \n",
    "base_dir = 'PenData'  # Replace with your actual directory path\n",
    "train_labels_dir = os.path.join(base_dir, 'train/labels')\n",
    "valid_labels_dir = os.path.join(base_dir, 'valid/labels')\n",
    "test_labels_dir = os.path.join(base_dir, 'test/labels')\n",
    "\n",
    "update_class_ids(train_labels_dir, '3')\n",
    "update_class_ids(valid_labels_dir, '3')\n",
    "update_class_ids(test_labels_dir, '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                \n",
    "base_dir = 'Pen_dataset3'  # Replace with your actual directory path\n",
    "train_labels_dir = os.path.join(base_dir, 'train/labels')\n",
    "valid_labels_dir = os.path.join(base_dir, 'valid/labels')\n",
    "test_labels_dir = os.path.join(base_dir, 'test/labels')\n",
    "\n",
    "update_class_ids(train_labels_dir, '3')\n",
    "update_class_ids(valid_labels_dir, '3')\n",
    "update_class_ids(test_labels_dir, '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bottle Dataset:2\n",
    "\n",
    "\n",
    "# Define your directories for the pen dataset\n",
    "base_dir = 'Bottle_dataset'  # Replace with your actual directory path\n",
    "train_labels_dir = os.path.join(base_dir, 'train/labels')\n",
    "valid_labels_dir = os.path.join(base_dir, 'valid/labels')\n",
    "test_labels_dir = os.path.join(base_dir, 'test/labels')\n",
    "\n",
    "# Update class IDs to '80' for pen\n",
    "update_class_ids(train_labels_dir, '2')\n",
    "update_class_ids(valid_labels_dir, '2')\n",
    "update_class_ids(test_labels_dir, '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glass dataset:\n",
      "Number of train images: 87\n",
      "Number of train labels: 87\n",
      "Number of valid images: 22\n",
      "Number of valid labels: 22\n",
      "\n",
      "Pen dataset:\n",
      "Number of train images: 90\n",
      "Number of train labels: 90\n",
      "Number of valid images: 27\n",
      "Number of valid labels: 27\n",
      "Datasets merged successfully.\n",
      "\n",
      "Merged dataset:\n",
      "Number of train images after merge: 2560\n",
      "Number of train labels after merge: 2560\n",
      "Number of valid images after merge: 116\n",
      "Number of valid labels after merge: 116\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define your directory paths for each dataset\n",
    "glass_dataset_dir = 'glasses_yolomodel_dataset'  # replace with your path\n",
    "glass_dataset_dir2 = 'Specsnospecs'\n",
    "glass_dataset_dir3 = 'GlassesDataset2'\n",
    "pen_dataset_dir = 'PenData'  # replace with your path\n",
    "pen_dataset_dir2 = 'PenDataset2'\n",
    "bottle_dataset_dir = 'Bottle_dataset'\n",
    "merged_dataset_dir = 'merged_dataset'  # replace with your path for the new merged dataset\n",
    "\n",
    "# Create directories in the merged dataset if they don't exist\n",
    "os.makedirs(os.path.join(merged_dataset_dir, 'images/train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(merged_dataset_dir, 'images/valid'), exist_ok=True)\n",
    "os.makedirs(os.path.join(merged_dataset_dir, 'labels/train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(merged_dataset_dir, 'labels/valid'), exist_ok=True)\n",
    "\n",
    "def count_files(directory):\n",
    "    return len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n",
    "\n",
    "\n",
    "print(\"Glass dataset:\")\n",
    "for split in ['train', 'valid']:\n",
    "    images_source_dir = os.path.join(glass_dataset_dir, split, 'images')\n",
    "    labels_source_dir = os.path.join(glass_dataset_dir, split, 'labels')\n",
    "    print(f\"Number of {split} images: {count_files(images_source_dir)}\")\n",
    "    print(f\"Number of {split} labels: {count_files(labels_source_dir)}\")\n",
    "\n",
    "# Count files in the original pen dataset\n",
    "print(\"\\nPen dataset:\")\n",
    "for split in ['train', 'valid']:\n",
    "    images_source_dir = os.path.join(pen_dataset_dir, split, 'images')\n",
    "    labels_source_dir = os.path.join(pen_dataset_dir, split, 'labels')\n",
    "    print(f\"Number of {split} images: {count_files(images_source_dir)}\")\n",
    "    print(f\"Number of {split} labels: {count_files(labels_source_dir)}\")\n",
    "\n",
    "def merge_glass_dataset(pen_dataset_dir, merged_dataset_dir):\n",
    "    for split in ['train', 'valid']:\n",
    "        # Define the source and destination directories\n",
    "        images_source_dir = os.path.join(pen_dataset_dir, split, 'images')\n",
    "        labels_source_dir = os.path.join(pen_dataset_dir, split, 'labels')\n",
    "        images_dest_dir = os.path.join(merged_dataset_dir, 'images', split)\n",
    "        labels_dest_dir = os.path.join(merged_dataset_dir, 'labels', split)\n",
    "\n",
    "        # Copy images\n",
    "        for item in os.listdir(images_source_dir):\n",
    "            shutil.copy2(os.path.join(images_source_dir, item), images_dest_dir)\n",
    "\n",
    "        # Copy labels\n",
    "        for item in os.listdir(labels_source_dir):\n",
    "            shutil.copy2(os.path.join(labels_source_dir, item), labels_dest_dir)\n",
    "\n",
    "def merge_pen_dataset(pen_dataset_dir, merged_dataset_dir):\n",
    "    for split in ['train', 'valid']:\n",
    "        # Define the source and destination directories\n",
    "        images_source_dir = os.path.join(pen_dataset_dir, split, 'images')\n",
    "        labels_source_dir = os.path.join(pen_dataset_dir, split, 'labels')\n",
    "        images_dest_dir = os.path.join(merged_dataset_dir, 'images', split)\n",
    "        labels_dest_dir = os.path.join(merged_dataset_dir, 'labels', split)\n",
    "\n",
    "        # Copy images\n",
    "        for item in os.listdir(images_source_dir):\n",
    "            shutil.copy2(os.path.join(images_source_dir, item), images_dest_dir)\n",
    "\n",
    "        # Copy labels\n",
    "        for item in os.listdir(labels_source_dir):\n",
    "            shutil.copy2(os.path.join(labels_source_dir, item), labels_dest_dir)\n",
    "\n",
    "# Execute the merge functions\n",
    "merge_glass_dataset(glass_dataset_dir, merged_dataset_dir)\n",
    "merge_pen_dataset(glass_dataset_dir2, merged_dataset_dir)\n",
    "merge_pen_dataset(glass_dataset_dir3, merged_dataset_dir)\n",
    "merge_pen_dataset(pen_dataset_dir, merged_dataset_dir)\n",
    "merge_pen_dataset(pen_dataset_dir2, merged_dataset_dir)\n",
    "merge_pen_dataset(bottle_dataset_dir, merged_dataset_dir)\n",
    "\n",
    "print(\"Datasets merged successfully.\")\n",
    "print(\"\\nMerged dataset:\")\n",
    "for split in ['train', 'valid']:\n",
    "    images_dest_dir = os.path.join(merged_dataset_dir, 'images', split)\n",
    "    labels_dest_dir = os.path.join(merged_dataset_dir, 'labels', split)\n",
    "    print(f\"Number of {split} images after merge: {count_files(images_dest_dir)}\")\n",
    "    print(f\"Number of {split} labels after merge: {count_files(labels_dest_dir)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 2220\n",
      "Number of validation images: 555\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "# Define your directory paths for each dataset\n",
    "dataset_dirs = ['glasses_yolomodel_dataset', 'Specsnospecs', 'GlassesDataset2', 'PenData', 'PenDataset2','Pen_dataset3', 'Bottle_dataset']\n",
    "merged_dataset_dir = 'merged_dataset2'  # replace with your path for the new merged dataset\n",
    "\n",
    "# Create directories in the merged dataset if they don't exist\n",
    "os.makedirs(os.path.join(merged_dataset_dir, 'images/train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(merged_dataset_dir, 'images/valid'), exist_ok=True)\n",
    "os.makedirs(os.path.join(merged_dataset_dir, 'labels/train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(merged_dataset_dir, 'labels/valid'), exist_ok=True)\n",
    "\n",
    "# Function to pair images with labels\n",
    "def pair_images_with_labels(images_dir, labels_dir):\n",
    "    paired_files = []\n",
    "    for image_name in os.listdir(images_dir):\n",
    "        if not image_name.lower().endswith(('.png', '.jpeg', '.jpg')):\n",
    "            continue\n",
    "        label_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "        image_path = os.path.join(images_dir, image_name)\n",
    "        label_path = os.path.join(labels_dir, label_name)\n",
    "        if os.path.isfile(image_path) and os.path.isfile(label_path):\n",
    "            paired_files.append((image_path, label_path))\n",
    "    return paired_files\n",
    "\n",
    "# Collect and pair all image files from all dataset directories\n",
    "all_paired_files = []\n",
    "for dir_path in dataset_dirs:\n",
    "    images_dir_train = os.path.join(dir_path, 'train/images')\n",
    "    labels_dir_train = os.path.join(dir_path, 'train/labels')\n",
    "    all_paired_files.extend(pair_images_with_labels(images_dir_train, labels_dir_train))\n",
    "\n",
    "    images_dir_valid = os.path.join(dir_path, 'valid/images')\n",
    "    labels_dir_valid = os.path.join(dir_path, 'valid/labels')\n",
    "    all_paired_files.extend(pair_images_with_labels(images_dir_valid, labels_dir_valid))\n",
    "\n",
    "    # Uncomment the following lines if you want to include 'test' images and labels as well\n",
    "    # images_dir_test = os.path.join(dir_path, 'test/images')\n",
    "    # labels_dir_test = os.path.join(dir_path, 'test/labels')\n",
    "    # all_paired_files.extend(pair_images_with_labels(images_dir_test, labels_dir_test))\n",
    "\n",
    "# Randomly shuffle the paired files before splitting\n",
    "random.shuffle(all_paired_files)\n",
    "\n",
    "# Split the files into train and validation sets (80/20 split)\n",
    "split_index = int(0.8 * len(all_paired_files))\n",
    "train_files = all_paired_files[:split_index]\n",
    "valid_files = all_paired_files[split_index:]\n",
    "\n",
    "# Copy the files to the new training and validation directories\n",
    "def copy_files(file_pairs, images_dest_dir, labels_dest_dir):\n",
    "    for image_path, label_path in file_pairs:\n",
    "        shutil.copy2(image_path, images_dest_dir)\n",
    "        shutil.copy2(label_path, labels_dest_dir)\n",
    "\n",
    "copy_files(train_files, os.path.join(merged_dataset_dir, 'images/train'), os.path.join(merged_dataset_dir, 'labels/train'))\n",
    "copy_files(valid_files, os.path.join(merged_dataset_dir, 'images/valid'), os.path.join(merged_dataset_dir, 'labels/valid'))\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of training images: {len(train_files)}\")\n",
    "print(f\"Number of validation images: {len(valid_files)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
